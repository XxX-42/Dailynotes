import re
import os
import hashlib
import difflib
import unicodedata  # [NEW] å¼•å…¥ unicode æ”¯æŒ
from config import Config
from .utils import FileUtils, Logger


class FormatCore:
    @staticmethod
    def _enforce_hyphen_space(line: str, context: str = "", filename: str = "") -> str:
        return line

    @staticmethod
    def normalize_indentation(content: str) -> str:
        return re.sub(r'(?m)^( +)', lambda m: m.group(1).replace('    ', '\t'), content)

    @staticmethod
    def auto_format_links(content: str) -> str:
        # [FIX] Escape brackets properly to avoid "nested set" warning
        pattern = r'(?<![\[\(\<])(https?://([^/\s\n]+)(?:/[^\s\n]*)?)'

        def _replacer(match): return f"[{match.group(2)}]({match.group(1)})"

        return re.sub(pattern, _replacer, content)

    @staticmethod
    def format_image_links(content: str) -> str:
        ext_pattern = re.compile(r'\.(png|jpe?g|gif|bmp|svg|pdf)$', re.IGNORECASE)

        def _replacer(match):
            inner = match.group(1)
            base = inner.split('|')[0]
            if ext_pattern.search(base): return f"![[{base}{Config.IMAGE_PARAM_SUFFIX}]]"
            return match.group(0)

        return re.sub(r'!\[\[([^\]]+)\]\]', _replacer, content)

    @staticmethod
    def sanitize_markdown_links(content: str) -> str:
        invalid_chars = r'[\\:]'

        def _clean_wiki(m): return f"[[{re.sub(invalid_chars, '', m.group(1)).strip()}]]"

        content = re.sub(r'\[\[(.*?)\]\]', _clean_wiki, content)

        def _clean_std(m): return f"[{re.sub(invalid_chars, '', m.group(1)).strip()}]({m.group(2)})"

        return re.sub(r'\[([^\]]+?)\]\(([^)]+?)\)', _clean_std, content)

    @staticmethod
    def get_header_sorting_key(title_line: str) -> str:
        """
        [FIX] ä¿®å¤ä¸­æ–‡æ ‡é¢˜è¢«è¿‡æ»¤ä¸ºç©ºå­—ç¬¦ä¸²å¯¼è‡´æ’åºæ··ä¹±çš„é—®é¢˜
        """
        # 1. ç§»é™¤ Markdown æ ‡è®° (#, [[, ]])
        clean_title = re.sub(r'[#\[\]]', '', title_line).strip().lower()
        # 2. å¦‚æœæ¸…ç†åä¸ä¸ºç©ºï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™ï¼ˆçº¯ç¬¦å·æ ‡é¢˜ï¼‰ä½¿ç”¨åŸå­—ç¬¦ä¸²
        # è¿™æ ·ç¡®ä¿ "æµ‹è¯•" å’Œ "è°ƒè¯•" æœ‰ä¸åŒçš„ Key
        return clean_title if clean_title else title_line.strip()

    @staticmethod
    def _extract_sort_key(block_lines: list) -> tuple:
        """
        [SyncCore ä¸€è‡´æ€§ä¿è¯]
        ä¸¥æ ¼å¯¹é½ SyncCore çš„ _calculate_sort_key é€»è¾‘
        è¿”å›: (has_time_bool, time_val, block_id)
        """
        if not block_lines: return (1, "99:99", "zzzzzz")
        first_line = block_lines[0].strip()

        # 1. Block ID
        id_match = re.search(r'\^([a-zA-Z0-9]{6,})\s*$', first_line)
        bid = id_match.group(1) if id_match else "zzzzzz"

        # 2. Time
        time_match = re.search(r'(\d{1,2}:\d{2})', first_line)
        if time_match:
            has_time = 0  # æœ‰æ—¶é—´æ’å‰é¢
            time_val = time_match.group(1).zfill(5)
        else:
            has_time = 1  # æ— æ—¶é—´æ’åé¢
            time_val = "99:99"

        return (has_time, time_val, bid)

    @classmethod
    def sort_day_planner_content(cls, content: str) -> str:
        if not content.strip(): return ""
        lines = content.split('\n')
        preamble = []
        blocks = []
        current_block = []
        in_task_block = False

        # [FIX] ä»…åŒ¹é…è¡Œé¦–é¡¶æ ¼çš„ä»»åŠ¡ä½œä¸ºå—çš„èµ·ç‚¹ (ç§»é™¤ ^[\t\s]*)
        # è¿™æ ·ç¼©è¿›çš„å­ä»»åŠ¡ã€å›¾ç‰‡ä¼šä½œä¸º"å†…å®¹"ç•™åœ¨å½“å‰å—ä¸­ï¼Œä¸ä¼šè¢«æ‹†åˆ†
        task_start_pattern = re.compile(r'^-\s+\[[xX\s]\]')

        for line in lines:
            is_task_start = bool(task_start_pattern.match(line))
            if is_task_start:
                if current_block: blocks.append(current_block)
                current_block = [line]
                in_task_block = True
            elif in_task_block:
                # é‡åˆ°ç©ºè¡Œæˆ–åˆ†éš”ç¬¦æ‰ç»“æŸå½“å‰å—
                if line.strip() == "" or line.strip().startswith('---'):
                    if current_block: blocks.append(current_block)
                    current_block = []
                    in_task_block = False
                    if line.strip(): preamble.append(line)
                else:
                    current_block.append(line)
            else:
                preamble.append(line)

        if current_block: blocks.append(current_block)

        # æ’åº (ä½¿ç”¨æ›´æ–°åçš„ Key)
        sorted_blocks = sorted(blocks, key=cls._extract_sort_key)

        output = []
        p_text = "\n".join(preamble).strip()
        if p_text: output.append(p_text)

        for blk in sorted_blocks:
            # å—å†…éƒ¨ä½¿ç”¨å•æ¢è¡Œæ‹¼æ¥ï¼Œä¿æŒç´§å‡‘
            blk_text = "\n".join(blk).rstrip()
            output.append(blk_text)

        # å—ä¹‹é—´ä½¿ç”¨åŒæ¢è¡Œæ‹¼æ¥ (é¡¶å±‚ä»»åŠ¡ä¹‹é—´ç•™ç©º)
        return "\n\n".join(output).strip()

    @classmethod
    def sort_markdown_sections(cls, text: str, filename: str = "") -> str:
        if not text.strip(): return text

        sections = re.split(r'^(#\s.*)$', text.strip(), flags=re.MULTILINE)
        output = []

        start_idx = 0
        if sections and not sections[0].startswith('#'):
            output.append(sections[0].strip())
            start_idx = 1

        i = start_idx
        while i < len(sections):
            title = sections[i].strip() if i < len(sections) else ""
            content = sections[i + 1] if i + 1 < len(sections) else ""

            l1_key = cls.get_header_sorting_key(title)
            is_target_section = "dayplanner" in l1_key or "journey" in l1_key

            # [FIX] ä½¿ç”¨ unicodedata.normalize ç¡®ä¿å†…å®¹å¤„ç†çš„ä¸€è‡´æ€§
            sub_blocks = re.split(r'^(##\s.*)$', content, flags=re.MULTILINE)

            processed_sub_sections = []

            pre_l2 = sub_blocks[0].strip()
            if pre_l2:
                if is_target_section:
                    processed_sub_sections.append(cls.sort_day_planner_content(pre_l2))
                else:
                    processed_sub_sections.append(pre_l2)

            j = 1
            while j < len(sub_blocks):
                l2_title = sub_blocks[j].strip()
                l2_content = sub_blocks[j + 1].strip() if j + 1 < len(sub_blocks) else ""

                final_l2_content = ""
                if l2_content:
                    if is_target_section:
                        final_l2_content = cls.sort_day_planner_content(l2_content)
                    else:
                        final_l2_content = l2_content

                if final_l2_content:
                    processed_sub_sections.append(f"{l2_title}\n\n{final_l2_content}")
                else:
                    processed_sub_sections.append(l2_title)

                j += 2

            full_section_content = "\n\n".join(processed_sub_sections).strip()

            if full_section_content:
                output.append(f"{title}\n\n{full_section_content}")
            else:
                output.append(title)

            i += 2

        return "\n\n".join(output).strip()

    @staticmethod
    def _log_diff(step_name: str, old_content: str, new_content: str):
        if old_content == new_content: return
        if Config.DEBUG_MODE:
            d = difflib.Differ()
            diff = list(d.compare(old_content.splitlines(), new_content.splitlines()))
            changed_lines = [line.strip() for line in diff if line.startswith('+ ') or line.startswith('- ')]
            if len(changed_lines) > 0:
                Logger.debug(f"=== [{step_name}] Format Changes ===")
                for l in changed_lines[:5]: Logger.debug(l)

    @classmethod
    def execute(cls, filepath: str) -> bool:
        if not os.path.exists(filepath): return False
        content = FileUtils.read_content(filepath)
        if not content: return False

        # [CRITICAL] 1. ç«‹å³å¼ºåˆ¶ NFC æ ‡å‡†åŒ–
        # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†æ¶ˆé™¤ macOS NFD æ–‡ä»¶åå’Œ Python å­—ç¬¦ä¸²ä¹‹é—´çš„éšå½¢å·®å¼‚
        content = unicodedata.normalize('NFC', content)

        orig_hash = hashlib.md5(content.encode('utf-8')).hexdigest()

        # Step 2: æ ‡å‡†åŒ–å¤„ç†
        c = cls.normalize_indentation(content)
        c = cls.auto_format_links(c)
        c = cls.sanitize_markdown_links(c)
        c = cls.format_image_links(c)

        # Step 3: æ’åºä¸æ’ç‰ˆ
        fname = os.path.basename(filepath)
        prev_text = c
        c = cls.sort_markdown_sections(c, filename=fname)

        cls._log_diff("FormatCore", prev_text, c)

        c = c.strip() + "\n"
        new_hash = hashlib.md5(c.encode('utf-8')).hexdigest()

        if orig_hash != new_hash:
            Logger.info(f"âœ¨ [Format] ä¼˜åŒ–æ—¥è®°æ’ç‰ˆä¸é—´è·: {fname}")
            return FileUtils.write_file(filepath, c)
        return False

    @staticmethod
    def fix_broken_tab_bullets_global():
        if not os.path.exists(Config.DAILY_NOTE_DIR): return
        pattern = re.compile(r'(?m)^(\t+)-(?![ \t])')
        for filename in os.listdir(Config.DAILY_NOTE_DIR):
            if not filename.endswith('.md'): continue
            filepath = os.path.join(Config.DAILY_NOTE_DIR, filename)
            try:
                content = FileUtils.read_content(filepath)
                if not content: continue
                new_content = pattern.sub(r'\1- ', content)
                if new_content != content:
                    FileUtils.write_file(filepath, new_content)
                    Logger.info(f"ğŸ”§ [Fix] ä¿®å¤åˆ—è¡¨ç¼©è¿›æ ¼å¼: {filename}")
            except Exception as e:
                Logger.debug(f"Global Fix Error {filename}: {e}")
