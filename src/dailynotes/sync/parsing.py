import re
import unicodedata

def get_indent_depth(line):
    """
    [Helper] ç»Ÿä¸€è®¡ç®—ç¼©è¿›è§†è§‰æ·±åº¦ (Tab=4 spaces)
    è§£å†³ Tab/Space æ··ç”¨å¯¼è‡´çš„å±‚çº§åˆ¤æ–­å¤±æ•ˆé—®é¢˜ã€‚
    """
    no_quote = re.sub(r'^>\s?', '', line)
    expanded = no_quote.expandtabs(4)
    return len(expanded) - len(expanded.lstrip())

def parse_yaml_tags(lines):
    tags = []
    if not lines or lines[0].strip() != '---': return []
    in_yaml = False
    for i, line in enumerate(lines):
        if i == 0: in_yaml = True; continue
        if line.strip() == '---': break
        if in_yaml and ('tags:' in line or 'main' in line):
            if re.search(r'\bmain\b', line): tags.append('main')
    return tags

def clean_task_text(line, block_id=None, context_name=None):
    """
    [v10.7 Aggressive Clean]
    å¢åŠ é€šç”¨å°¾éƒ¨æ¸…ç†ï¼Œé˜²æ­¢æ•‘æ´æ¨¡å¼ä¸‹æ®‹ç¼º ID (å¦‚ ^04cn) æœªè¢«æ¸…é™¤å¯¼è‡´ ID é‡å¤ã€‚
    [v10.8 Time Strip] å¢åŠ æ—¶é—´æ®µå‰¥ç¦»ï¼Œé˜²æ­¢ 07:00 - 11:20 æ±¡æŸ“æºæ–‡ä»¶ã€‚
    """
    # 1. ç§»é™¤ Checkbox (ä¿ç•™)
    line = re.sub(r'^\s*-\s*\[.\]\s?', '', line)

    # === [æ–°å¢] 2. ç§»é™¤ Day Planner æ—¶é—´æ®µ ===
    # åŒ¹é…: "07:00 " æˆ– "07:00 - 11:20 "
    # é€»è¾‘: åªæœ‰ä½äºè¡Œé¦–ï¼ˆå»é™¤ checkbox åï¼‰çš„æ—¶é—´æ‰ä¼šè¢«è§†ä¸ºè°ƒåº¦ä¿¡æ¯
    line = re.sub(r'^\s*\d{1,2}:\d{2}(?:\s*-\s*\d{1,2}:\d{2})?\s+', '', line)

    clean_text = line

    # 3. ç§»é™¤æŒ‡å®šå— ID (åŸé€»è¾‘)
    if block_id:
        clean_text = re.sub(rf'(?<=\s)\^{re.escape(block_id)}\s*$', '', clean_text)

    # 4. é€šç”¨å°¾éƒ¨æ¸…ç† (åŸé€»è¾‘)
    clean_text = re.sub(r'\s+\^[a-zA-Z0-9]*$', '', clean_text)

    # 5. ç§»é™¤æ—¥æœŸé“¾æ¥ (åŸé€»è¾‘)
    clean_text = re.sub(r'\[\[\d{4}-\d{2}-\d{2}(?:#\^[a-zA-Z0-9]+)?(?:\|.*?)?\]\]', '', clean_text)

    # 6. ç§»é™¤æ–‡ä»¶è‡ªèº«é“¾æ¥ (åŸé€»è¾‘)
    if context_name:
        clean_text = re.sub(rf'\[\[{re.escape(context_name)}(?:#\^[a-zA-Z0-9]+)?(?:\|.*?)?\]\]', '', clean_text)

    # 7. ç§»é™¤ Emoji æ—¥æœŸ (åŸé€»è¾‘)
    clean_text = re.sub(r'[ğŸ“…âœ…]\s*\d{4}-\d{2}-\d{2}', '', clean_text)
    clean_text = re.sub(r'\(connect::.*?\)', '', clean_text)

    return clean_text.strip()

def normalize_block_content(block_lines):
    normalized = []
    for line in block_lines:
        clean = re.sub(r'^[\s>]+', '', line).strip()
        if not clean or clean in ['-', '- ']: continue
        normalized.append(clean)
    return "\n".join(normalized) + "\n"

def capture_block(lines, start_idx):
    """
    [v14.2 Indent-Priority Capture]
    ä¿®å¤åŒé‡ç¼©è¿›ä»»åŠ¡ (- [ ]) è¢«æˆªæ–­çš„ Bugã€‚
    æ ¸å¿ƒé€»è¾‘å˜æ›´ï¼šç¡®ç«‹ã€ç¼©è¿›éœ¸æƒã€‘ã€‚
    åªè¦å½“å‰è¡Œç¼©è¿› > çˆ¶çº§ç¼©è¿›ï¼Œæ— æ¡ä»¶è§†ä¸ºå­å†…å®¹ï¼Œè·³è¿‡ä»»ä½•å†…å®¹æ£€æŸ¥ï¼ˆå¦‚ # æˆ– ---ï¼‰ã€‚
    åªæœ‰ç¼©è¿› <= çˆ¶çº§æ—¶ï¼Œæ‰è¿›è¡Œç»“æŸåˆ¤å®šã€‚
    """
    if start_idx >= len(lines): return [], 0

    # 1. è·å–çˆ¶çº§ï¼ˆé”šç‚¹ï¼‰çš„è§†è§‰ç¼©è¿›æ·±åº¦
    base_depth = get_indent_depth(lines[start_idx])

    block = [lines[start_idx]]
    consumed = 1
    j = start_idx + 1

    while j < len(lines):
        nl = lines[j]

        # 1. ç©ºè¡Œå¤„ç†ï¼šå§‹ç»ˆä¿ç•™ï¼Œä¸ä½œä¸ºåˆ¤å®šä¾æ®
        if not nl.strip():
            block.append(nl)
            consumed += 1
            j += 1
            continue

        # 2. å¼ºåˆ†éš”ç¬¦ï¼šå”¯ä¸€çš„ä¾‹å¤–ï¼Œå¿…é¡»æˆªæ–­
        if nl.strip() == '----------': break

        # 3. è®¡ç®—å½“å‰è¡Œç¼©è¿›
        curr_depth = get_indent_depth(nl)

        # === [æ ¸å¿ƒä¿®å¤] ç¼©è¿›ä¼˜å…ˆåŸåˆ™ ===
        # å¦‚æœå½“å‰è¡Œæ¯”çˆ¶çº§ç¼©è¿›æ·±ï¼Œå®ƒå°±æ˜¯å­å…ƒç´ ã€‚
        # ä¸æ£€æŸ¥å®ƒæ˜¯å¦ä»¥ '#' å¼€å¤´ï¼Œä¹Ÿä¸åšä»»ä½•æ­£åˆ™æ¸…æ´—ã€‚
        # è¿™ä¿è¯äº† `      - [ ]` è¿™ç§ç»“æ„ç»å¯¹ä¼šè¢«æ•è·ã€‚
        if curr_depth > base_depth:
            block.append(nl)
            consumed += 1
            j += 1
            continue

        # 4. åªæœ‰å½“ç¼©è¿› <= çˆ¶çº§æ—¶ï¼Œæ‰è§†ä¸ºæ½œåœ¨çš„ç»“æŸ
        # æ­¤æ—¶é‡åˆ°åŒçº§ä»»åŠ¡ã€åŒçº§æ ‡é¢˜æˆ–æ›´æµ…çš„å†…å®¹ï¼Œå‡ç»“æŸæ•è·
        break

    return block, consumed

def extract_routing_target(line, file_path_map):
    clean = re.sub(r'\[\[[^\]]*?\#\^[a-zA-Z0-9]{6,}\|[âš“\*ğŸ”—â®ğŸ“…]\]\]', '', line)
    matches = re.findall(r'\[\[(.*?)\]\]', clean)
    for match in matches:
        pot = match.split('|')[0]
        pot = unicodedata.normalize('NFC', pot)
        if pot in file_path_map: return file_path_map[pot]
    return None
